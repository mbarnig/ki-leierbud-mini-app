{"pageProps":{"title":"Les machines qui génèrent des images","content":"\n<h2 class=\"wp-block-heading\">Les machines qui génèrent des images</h2>\n\n\n\n<p>L’histoire de la génération d’images par intelligence artificielle sera développée dans plusieurs chapitres spécifiques. J’en résume ici les premières étapes marquantes :</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>1972&nbsp;: Harold Cohen, pionnier à la croisée de l’IA et des arts visuels, crée&nbsp;AARON, un programme informatique révolutionnaire conçu pour générer de manière autonome des peintures et des dessins. Son approche novatrice, mêlant créativité computationnelle et art traditionnel, lui vaut une renommée internationale. Les œuvres d’AARON sont exposées dans de nombreux musées prestigieux à travers le monde, et Cohen reçoit plusieurs distinctions au cours de sa carrière.</li>\n\n\n\n<li>Années 1990–2000&nbsp;: les premiers algorithmes évolutifs, fractals et générateurs procéduraux, comme&nbsp;POV-Ray (Persistence of Vision Raytracer), permettent de créer des images abstraites ou des paysages virtuels. Ces productions restent toutefois éloignées du réalisme photographique.</li>\n\n\n\n<li>2014&nbsp;: Ian J. Goodfellow, alors chercheur chez Google Brain (et plus tard directeur de l’apprentissage automatique chez Apple), invente les&nbsp;GANs&nbsp;(<em>Generative Adversarial Networks</em>). Deux réseaux neuronaux y sont mis en compétition : l’un génère des images, l’autre les évalue. C’est une révolution : pour la première fois, l’IA produit des visages, objets et paysages réalistes. En&nbsp;2019, le site&nbsp;<em>This Person Does Not Exist</em>, qui génère des visages fictifs ultra-réalistes, fait sensation.</li>\n\n\n\n<li>2015&nbsp;: Des chercheurs de Google, notamment Alexander Mordvintsev, présentent&nbsp;DeepDream, une « machine à rêves » numérique qui transforme des images existantes en visions psychédéliques et devient rapidement virale sur Internet.</li>\n\n\n\n<li>2021 : OpenAI lance DALL-E, premier modèle capable de générer des images originales à partir de simples descriptions textuelles.</li>\n\n\n\n<li>2021 (juillet) : DALL-E mini, créé par Boris Dayma à la suite d’un hackathon organisé par Hugging Face et Google.</li>\n\n\n\n<li>2022 : explosion médiatique avec plusieurs modèles concurrents : DALL-E2 (OpenAI), Imagen (Google), MidJourney, et Stable Diffusion (Stability AI).</li>\n\n\n\n<li>2023&nbsp;: lancement de&nbsp;LetzAI, générateur d’images IA luxembourgeois. C’est la première plateforme à permettre la création conviviale de modèles personnalisés, avec ses propres personnages, objets et styles. Rapidement, LetzAI évolue et est aujourd’hui considéré comme l’un des écosystèmes visuels les plus performants au monde.</li>\n\n\n\n<li>2024 : DALL-E3 est intégré à ChatGPT et les générateurs d’images par IA s’invitent dans les outils de création grand public, comme Photoshop.</li>\n</ul>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<h3 class=\"wp-block-heading\">Mon expérience avec DALL-E2</h3>\n\n\n\n<p>J’ai découvert les premières images de DALL-E2 dans l’édition du 14 juillet 2022 du magazine renommé <em>IEEE Spectrum</em>. Certaines de ces illustrations m’ont profondément marqué.</p>\n\n\n\n<figure class=\"wp-block-gallery has-nested-images columns-default is-cropped wp-block-gallery-1 is-layout-flex wp-block-gallery-is-layout-flex\">\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"992\" height=\"992\" data-id=\"2496\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/spectrum-asked-for-a-picasso-style-painting-of-a-parrot-flipping-pancakes-and-dall-e-2-served-it-up-2.jpg\" alt=\"\" class=\"wp-image-2496\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/spectrum-asked-for-a-picasso-style-painting-of-a-parrot-flipping-pancakes-and-dall-e-2-served-it-up-2.jpg 992w, https://admin.ki-leierbud.lu/wp-content/uploads/spectrum-asked-for-a-picasso-style-painting-of-a-parrot-flipping-pancakes-and-dall-e-2-served-it-up-2-300x300.jpg 300w, https://admin.ki-leierbud.lu/wp-content/uploads/spectrum-asked-for-a-picasso-style-painting-of-a-parrot-flipping-pancakes-and-dall-e-2-served-it-up-2-150x150.jpg 150w, https://admin.ki-leierbud.lu/wp-content/uploads/spectrum-asked-for-a-picasso-style-painting-of-a-parrot-flipping-pancakes-and-dall-e-2-served-it-up-2-768x768.jpg 768w\" sizes=\"auto, (max-width: 992px) 100vw, 992px\" /><figcaption class=\"wp-element-caption\">A Picasso-style painting of a parrot flipping pancakes</figcaption></figure>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"992\" height=\"992\" data-id=\"2497\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/a-cartoon-shows-a-panda-with-bamboo-sticking-out-of-its-mouth-and-a-sad-expression-on-its-face-looking-at-a-small-robot-2.jpg\" alt=\"\" class=\"wp-image-2497\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/a-cartoon-shows-a-panda-with-bamboo-sticking-out-of-its-mouth-and-a-sad-expression-on-its-face-looking-at-a-small-robot-2.jpg 992w, https://admin.ki-leierbud.lu/wp-content/uploads/a-cartoon-shows-a-panda-with-bamboo-sticking-out-of-its-mouth-and-a-sad-expression-on-its-face-looking-at-a-small-robot-2-300x300.jpg 300w, https://admin.ki-leierbud.lu/wp-content/uploads/a-cartoon-shows-a-panda-with-bamboo-sticking-out-of-its-mouth-and-a-sad-expression-on-its-face-looking-at-a-small-robot-2-150x150.jpg 150w, https://admin.ki-leierbud.lu/wp-content/uploads/a-cartoon-shows-a-panda-with-bamboo-sticking-out-of-its-mouth-and-a-sad-expression-on-its-face-looking-at-a-small-robot-2-768x768.jpg 768w\" sizes=\"auto, (max-width: 992px) 100vw, 992px\" /><figcaption class=\"wp-element-caption\">New Yorker-style cartoon of an unemployed panda eating bamboo realizing her job has been taken by a robot</figcaption></figure>\n</figure>\n\n\n\n<p></p>\n\n\n\n<p>Le modèle neuronal DALL-E2 avait été entraîné sur environ 650 millions d’images, extraites d’Internet et accompagnées de descriptions textuelles. À ce moment-là, le modèle n’était pas public : seuls quelques chercheurs sélectionnés y avaient accès pour l’évaluer.</p>\n\n\n\n<p>Quelques jours plus tard, OpenAI annonçait que le&nbsp;million d’usagers inscrits sur une liste d’attente&nbsp;seraient progressivement invités à tester une version bêta. Je m’étais moi aussi inscrit.</p>\n\n\n\n<p>Pour prévenir les abus, OpenAI avait imposé des garde-fous : interdiction de générer des contenus violents, racistes ou pornographiques, et impossibilité de créer des visages humains réalistes.</p>\n\n\n\n<p>En attendant d’être invité à tester DALL-E2, je me suis tourné vers DALL-E mini, développé par Boris Dayma. Publié d’abord sur la plateforme communautaire HuggingFace, le modèle, devenu viral, a ensuite été hébergé sur un site dédié : craiyon.com. Certes, ce modèle n’avait ni la résolution ni la performancede son «grand frère», mais il permettait déjà d’entrevoir le potentiel disruptif de cette technologie. Tout comme DALL-E2, il empêchait la génération de visages réalistes.</p>\n\n\n\n<p>Lorsqu’on soumettait une description sur Craiyon,&nbsp;16 images en basse résolution&nbsp;étaient produites, et les&nbsp;9 meilleures s’affichaient à l’écran.</p>\n\n\n\n<figure class=\"wp-block-gallery has-nested-images columns-default is-cropped wp-block-gallery-2 is-layout-flex wp-block-gallery-is-layout-flex\">\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"760\" height=\"931\" data-id=\"2499\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/painting_of_a_teddy_riding_a_horse-1.png\" alt=\"\" class=\"wp-image-2499\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/painting_of_a_teddy_riding_a_horse-1.png 760w, https://admin.ki-leierbud.lu/wp-content/uploads/painting_of_a_teddy_riding_a_horse-1-245x300.png 245w\" sizes=\"auto, (max-width: 760px) 100vw, 760px\" /><figcaption class=\"wp-element-caption\">A teddy riding a horse</figcaption></figure>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"760\" height=\"926\" data-id=\"2500\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/1659781040116-1.png\" alt=\"\" class=\"wp-image-2500\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/1659781040116-1.png 760w, https://admin.ki-leierbud.lu/wp-content/uploads/1659781040116-1-246x300.png 246w\" sizes=\"auto, (max-width: 760px) 100vw, 760px\" /><figcaption class=\"wp-element-caption\">A rabbit and a hedgehog at the beach</figcaption></figure>\n</figure>\n\n\n\n<p></p>\n\n\n\n<p>Le 15 août 2022, j’ai enfin reçu la confirmation qu’OpenAI avait accepté ma candidature pour participer aux tests de DALL-E2. Je me suis empressé d’effectuer mes premiers essais.</p>\n\n\n\n<p>Mon tout premier prompt était :<br><em>“cartoon of an elephant and a giraffe riding a bicycle on the beach”</em></p>\n\n\n\n<p>Parmi les quatre images générées, chacune en&nbsp;1024 x 1024 pixels, j’ai choisi celle qui me plaisait le plus :</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"1024\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/DALL·E-2022-08-15-11.50.14-cartoon-of-an-elephant-and-a-giraffe-riding-a-bicycle-on-the-beach.png\" alt=\"\" class=\"wp-image-2501\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/DALL·E-2022-08-15-11.50.14-cartoon-of-an-elephant-and-a-giraffe-riding-a-bicycle-on-the-beach.png 1024w, https://admin.ki-leierbud.lu/wp-content/uploads/DALL·E-2022-08-15-11.50.14-cartoon-of-an-elephant-and-a-giraffe-riding-a-bicycle-on-the-beach-300x300.png 300w, https://admin.ki-leierbud.lu/wp-content/uploads/DALL·E-2022-08-15-11.50.14-cartoon-of-an-elephant-and-a-giraffe-riding-a-bicycle-on-the-beach-150x150.png 150w, https://admin.ki-leierbud.lu/wp-content/uploads/DALL·E-2022-08-15-11.50.14-cartoon-of-an-elephant-and-a-giraffe-riding-a-bicycle-on-the-beach-768x768.png 768w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>cartoon of an elephant and a giraffe riding a bicycle on the beach</em> (août 2022)</figcaption></figure></div>\n\n\n<p></p>\n\n\n\n<p>J’étais fasciné par cette technologie et j’utilisais chaque jour tous mes crédits gratuits. Je publiais régulièrement mes meilleures créations comme&nbsp;<em>image du jour</em>&nbsp;sur&nbsp;Facebook, Instagram et LinkedIn.</p>\n\n\n\n<p>Le prompt avec l’éléphant et la girafe est d’ailleurs resté mon test favori : je l’utilise encore aujourd’hui pour comparer les résultats des nouveaux générateurs d’images, y compris des modèles chinois.</p>\n","colors":{"header":"#003366","main":"#E6F2FF","footer":"#004080","headerFont":"#FFFFFF","mainFont":"#000000","footerFont":"#FFFFFF"},"links":{"login":"https://www.web3.lu/ki-leierbud/login.html","about":"https://www.web3.lu/ki-leierbud/about.html","welcome":"https://www.web3.lu/ki-leierbud/welcome.html","search":"https://www.web3.lu/ki-leierbud/search.html","landing":"https://www.web3.lu/ki-leierbud/landing.html","dashboard":"https://www.web3.lu/ki-leierbud/dashboard.html","faq":"https://www.web3.lu/ki-leierbud/faq.html","user":"https://www.web3.lu/ki-leierbud/user.html","author":"https://www.web3.lu/ki-leierbud/author.html"},"logo":"assets/logo.svg","favicon":"assets/logo.svg","lang":"fr","langOptions":[{"lc":"fr","id":"2494"}],"prevHref":"/histoire/fr/2487/","nextHref":"/histoire/fr/2511/","position":"4/12","authorInitials":"MB"},"__N_SSG":true}