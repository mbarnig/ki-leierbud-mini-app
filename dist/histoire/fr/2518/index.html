<!DOCTYPE html><html><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" data-next-head=""/><title data-next-head="">Les machines qui parlent notre langue</title><link rel="icon" href="assets/logo.svg" data-next-head=""/><link rel="preload" href="/histoire/_next/static/css/6a90bc65f5e25b7d.css" as="style"/><style data-next-head="">
          :root{
            --color-header:#003366;
            --color-main:#E6F2FF;
            --color-footer:#004080;
            --text-header:#FFFFFF;
            --text-main:#000000;
            --text-footer:#FFFFFF;
          }
        </style><link rel="stylesheet" href="/histoire/_next/static/css/6a90bc65f5e25b7d.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/histoire/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/histoire/_next/static/chunks/webpack-c0ab7466c2010b5f.js" defer=""></script><script src="/histoire/_next/static/chunks/framework-b1e5f14688f9ffe6.js" defer=""></script><script src="/histoire/_next/static/chunks/main-e1696e71c401f547.js" defer=""></script><script src="/histoire/_next/static/chunks/pages/_app-83bffd16e2386ef9.js" defer=""></script><script src="/histoire/_next/static/chunks/pages/%5Blang%5D/%5Bslug%5D-37bdb02bf0c28ae7.js" defer=""></script><script src="/histoire/_next/static/rQNnZtZ66eHWK4CySTAhx/_buildManifest.js" defer=""></script><script src="/histoire/_next/static/rQNnZtZ66eHWK4CySTAhx/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="page-shell"></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"title":"Les machines qui parlent notre langue","content":"\n\u003ch2 class=\"wp-block-heading\"\u003eLes machines qui parlent notre langue\u003c/h2\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003ePour s’entretenir avec une machine en langage naturel, il faut qu’elle puisse répondre par la voix. La technologie qui rend cela possible est la synthèse vocale, connue sous le sigle TTS (Text-to-Speech).\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eJ’ai toujours été fasciné par cette technologie. En 1976, j’ai supervisé un travail de diplôme à l’Institut d’Électronique de l’EPFZ, réalisé par Kurt Mühlemann. L’objectif était de créer un circuit de synthèse vocale avec des filtres réglés. À la fin, le synthétiseur était capable de prononcer la phrase « Ich bin ein Computer », avec une tonalité résolument robotique.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eEn 2020, j’ai publié un livre retraçant l’histoire de la synthèse vocale mécanique, électrique, électronique et informatique, sous le titre Synthèse de la Parole.\u003c/p\u003e\n\n\n\n\u003cp\u003eOn y trouve, entre autres, Pedro the Voder, présenté à l’Exposition universelle de New York en 1939, l’Orator Verbis Electris (OVE-1, 1953\u003cstrong\u003e)\u003c/strong\u003e, le synthétiseur Parametric Artificial Talker (P.A.T., 1958), le Votrax (1970), le célèbre jouet éducatif Speak \u0026amp; Spell (1976), les programmes KlatTalk et  DECTalk (1982), ainsi que les systèmes Festival et Merlin, apparus à partir de 1984.\u003c/p\u003e\n\n\n\n\u003cp\u003eCes projets, ainsi que leurs inventeurs et inventrices, seront présentés en détail dans un chapitre spécifique.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eAujourd’hui, les sociétés GAFAM (Google, Apple, Facebook, Amazon, Microsoft) proposent des services de synthèse vocale dans le cloud avec des voix artificielles d’une telle qualité qu’il est souvent impossible de les distinguer d’une voix humaine. Hélas, la langue luxembourgeoise n’est pas encore prise en charge par ces grands acteurs.\u003c/p\u003e\n\n\n\n\u003ch3 class=\"wp-block-heading\"\u003e\u003cbr\u003eLes premiers pas au Luxembourg\u003c/h3\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eEn mars 2014, j’ai commencé à développer un module de synthèse vocale luxembourgeoise pour la version 1.48.4 du logiciel libre eSpeak. Ce projet avait été lancé en 1995 par Jonathan Duddington, jeune informaticien anglais, pour les ordinateurs personnels ACORN équipés du système d’exploitation RISC OS. Le système utilisait la méthode de synthèse par formants et reposait sur les phonèmes, c’est-à-dire les plus petits sons d’une langue qui permettent de distinguer les mots. On distingue notamment voyelles et consonnes, prononciation voisée (sonore) ou sourde.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003c/p\u003e\n\n\n\u003cdiv class=\"wp-block-image\"\u003e\n\u003cfigure class=\"aligncenter size-large\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"566\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/espeak-1024x566.png\" alt=\"\" class=\"wp-image-2626\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/espeak-1024x566.png 1024w, https://admin.ki-leierbud.lu/wp-content/uploads/espeak-300x166.png 300w, https://admin.ki-leierbud.lu/wp-content/uploads/espeak-768x425.png 768w, https://admin.ki-leierbud.lu/wp-content/uploads/espeak.png 1058w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\" /\u003e\u003cfigcaption class=\"wp-element-caption\"\u003eSpeak by Jonathan Duddington (1995)\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003cp\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e1995 était également l\u0026#8217;année de lancement d\u0026#8217;un projet majeur de synthèse vocale à la Faculté polytechnique de Mons (Belgique). Il s’agissait d’un projet de recherche européen, financé par la Commission européenne et dirigé par Thierry Dutoit.\u003c/p\u003e\n\n\n\n\u003cp\u003eLa méthode retenue reposait sur la\u0026nbsp;concaténation de diphones\u0026nbsp;— des segments de parole qui couvrent la transition entre deux phonèmes. Le système fut baptisé\u0026nbsp;MBROLA, acronyme de\u0026nbsp;\u003cem\u003eMulti-Band Resynthesis OverLap-Add\u003c/em\u003e. Cette approche constituait une variante optimisée de la technique\u0026nbsp;PSOLA (Pitch-Synchronous Overlap-Add), spécifiquement adaptée à la synthèse vocale par diphones.\u003c/p\u003e\n\n\n\n\u003cp\u003eMBROLA n’intégrait pas directement la conversion de texte en phonèmes : cette étape était généralement assurée par des outils complémentaires comme\u0026nbsp;eSpeak. Le projet avait toutefois une particularité novatrice pour l’époque : sa\u0026nbsp;distribution gratuite\u0026nbsp;était autorisée pour des usages\u0026nbsp;non commerciaux, notamment en\u0026nbsp;recherche\u0026nbsp;et en\u0026nbsp;éducation, ce qui a largement contribué à sa diffusion et à son succès académique.\u003c/p\u003e\n\n\n\n\u003cp\u003eJ’avais interrompu mon travail  sur eSpeak quand le projet plus avancé MaryLUX a été présenté en septembre 2015 à l’Université du Luxembourg par Ingmar Steiner, Jürgen Trouvain, Judith Manzoni et Peter Gilles. Ce système reposait sur MaryTTS, une technologie de synthèse vocale par sélection d’unités développée à l’Université de la Sarre dès les années 2000.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eEn septembre 2021, j’ai repris le développement du module luxembourgeois pour eSpeak, à la demande d’une personne aveugle qui souhaitait l’utiliser comme lecteur d’écran. C’était alors le seul moyen d’ajouter le luxembourgeois dans l’application libre NVDA (Non Visual Desktop Access), destinée aux aveugles et malvoyants. Le 11 novembre 2021, le luxembourgeois figurait comme 127e langue dans eSpeak-NG (nouvelle génération).\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003c/p\u003e\n\n\n\u003cdiv class=\"wp-block-image\"\u003e\n\u003cfigure class=\"aligncenter size-large\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"552\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/espeak-127-1024x552.png\" alt=\"\" class=\"wp-image-2623\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/espeak-127-1024x552.png 1024w, https://admin.ki-leierbud.lu/wp-content/uploads/espeak-127-300x162.png 300w, https://admin.ki-leierbud.lu/wp-content/uploads/espeak-127-768x414.png 768w, https://admin.ki-leierbud.lu/wp-content/uploads/espeak-127.png 1130w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\" /\u003e\u003cfigcaption class=\"wp-element-caption\"\u003ePull request for my luxembourgish eSpeak-NG module (November 2021)\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003cp\u003e\u003c/p\u003e\n\n\n\n\u003ch3 class=\"wp-block-heading\"\u003e\u003cbr\u003eL’apport de Coqui-AI\u003c/h3\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eL’année 2021 fut aussi marquée par la fondation de la start-up allemande Coqui-AI, qui ambitionnait de créer un écosystème européen dédié aux voix synthétiques. L’entreprise proposait une large gamme de modèles TTS basés sur des réseaux neuronaux modernes, accompagnés d’instructions détaillées pour les installer et les exécuter sur des ordinateurs personnels.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003ePour la première fois, la communauté mondiale des passionnés de TTS disposait d’un environnement complet pour se familiariser avec l’apprentissage profond, aujourd’hui méthode de référence pour la création de systèmes d’IA vocale. J’ai été un des utilisateurs de la première heure et, sans surprise, j’ai commencé mes essais par la création d’une voix synthétique luxembourgeoise.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eCet exemple est idéal pour expliquer quelles sont les données, compétences et infrastructures nécessaires pour développer une application d’IA. J’en présente ici les grandes lignes avant d’entrer dans les détails dans les chapitres suivants.\u003c/p\u003e\n\n\n\n\u003ch3 class=\"wp-block-heading\"\u003e\u003cbr\u003eLes ingrédients d’un modèle TTS\u003c/h3\u003e\n\n\n\n\u003ch4 class=\"wp-block-heading\"\u003e\u003cbr\u003eLe modèle TTS\u003c/h4\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eLa condition de départ est la disponibilité d’un modèle performant. Je ne détaillerai pas ici l’installation technique sur un ordinateur ou dans le cloud — c’est déjà une prouesse en soi — mais il faut savoir que le code est généralement partagé sur une plateforme de collaboration comme GitHub.\u003c/p\u003e\n\n\n\n\u003ch4 class=\"wp-block-heading\"\u003e\u003cbr\u003eLes données\u003c/h4\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eUn échantillon est constitué d’un enregistrement audio d’un texte parlé (de quelques secondes à une minute), accompagné d’un fichier texte avec la transcription et la séquence de phonèmes.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eLes enregistrements doivent idéalement être réalisés par un locuteur qualifié, dans un studio sans bruit de fond. Mais un seul échantillon ne suffit pas: il en faut des milliers pour entraîner un modèle. Dans une langue dite à faibles ressources comme le luxembourgeois, cela constitue un vrai défi. Les bases de données peuvent être hébergées sur la plateforme HuggingFace, ou sur le portail national data.public.lu s’il s’agit de données luxembourgeoises.\u003c/p\u003e\n\n\n\n\u003ch4 class=\"wp-block-heading\"\u003e\u003cbr\u003eL’entraînement\u003c/h4\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eAvant de lancer l’apprentissage, il faut paramétrer le modèle : nombre d’itérations, format audio, taille des échantillons, etc. Le processus d\u0026#8217;entraînement peut durer des heures, des jours, voire des semaines, selon la puissance de calcul disponible et le nombre d\u0026#8217;échantillons. L’entraîneur doit analyser régulièrement les logs d’entraînement et réagir aux éventuelles erreurs. En général, cette étape demande une expertise avancée, souvent de niveau doctorat.\u003c/p\u003e\n\n\n\n\u003ch4 class=\"wp-block-heading\"\u003e\u003cbr\u003eLa mise au point\u003c/h4\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eUne fois le modèle entraîné, il faut le mettre en production pour les utilisateurs, avec un guide d’usage et un dictionnaire des noms propres, mots étrangers et abréviations. Cette phase de finition requiert elle aussi des compétences spécialisées.\u003c/p\u003e\n\n\n\n\u003ch4 class=\"wp-block-heading\"\u003e\u003cbr\u003eLes premiers modèles luxembourgeois\u003c/h4\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003ePour entraîner mon premier modèle AI-TTS luxembourgeois fin 2021, j’ai utilisé la base de données MaryLUX. Pour le deuxième, j’ai ajouté des dictées disponibles sur le site de l’Université du Luxembourg, avec le consentement des trois oratrices et de Peter Gilles, linguiste et directeur du département des sciences humaines. J’ai publié les résultats sur mon site web le 6 janvier 2022.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eComme la qualité restait en deçà de l’état de l’art, j’ai enrichi la base avec des échantillons multilingues équilibrés (anglais, français, allemand, portugais) disponibles dans le domaine public, ce qui a permis de multiplier par cinq le volume d’entraînement. Le résultat fut un des premiers modèles TTS multilingues, présenté sur HuggingFace, et salué par la communauté comme par les responsables de Coqui-AI. Chaque voix pouvait synthétiser un texte dans les cinq langues, tout en conservant le charme de son accent natif.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003c/p\u003e\n\n\n\u003cdiv class=\"wp-block-image\"\u003e\n\u003cfigure class=\"aligncenter size-large\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"726\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/mir-schwaetzen-lb-1024x726.png\" alt=\"\" class=\"wp-image-2628\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/mir-schwaetzen-lb-1024x726.png 1024w, https://admin.ki-leierbud.lu/wp-content/uploads/mir-schwaetzen-lb-300x213.png 300w, https://admin.ki-leierbud.lu/wp-content/uploads/mir-schwaetzen-lb-768x544.png 768w, https://admin.ki-leierbud.lu/wp-content/uploads/mir-schwaetzen-lb-1536x1089.png 1536w, https://admin.ki-leierbud.lu/wp-content/uploads/mir-schwaetzen-lb.png 1848w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\" /\u003e\u003cfigcaption class=\"wp-element-caption\"\u003eMy HuggingFace demo space of a multilingual TTS model (2022)\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003cp\u003e\u003c/p\u003e\n\n\n\n\u003ch4 class=\"wp-block-heading\"\u003eLiesmaschinn.lu\u003c/h4\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eDepuis 2021, je collabore avec le Zenter fir d\u0026#8217;Lëtzebuerger Sprooch (ZLS). J’y ai appris que Max Kuborn, collaborateur de longue date de RTL, enregistrait des phrases en luxembourgeois pour documenter la prononciation des mots du LOD (Lëtzebuerger Online Dictionnaire). Convaincu de la valeur de ces données, j’ai demandé à obtenir une copie. \u003c/p\u003e\n\n\n\n\u003cp\u003eJe pariais que, vu la taille considérable de la base de données, il serait possible de se passer de l’étape intermédiaire des phonèmes et d’entraîner directement le modèle TTS à partir des\u0026nbsp;caractères alphabétiques. Autrement dit, au lieu d’utiliser une première application d’IA pour convertir le texte en phonèmes, puis une deuxième pour transformer ces phonèmes en sons, on pourrait imaginer un modèle capable d’apprendre directement la correspondance\u0026nbsp;lettres → sons\u0026nbsp;grâce à la masse de données disponibles.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eEn mars 2024, j’ai reçu un premier lot de fichiers. En juillet 2024, j’ai pu présenter une première version du modèle TTS, entraîné avec ces enregistrements, aux responsables du ZLS et au commissaire à la langue luxembourgeoise, Pierre Reding. Tous furent impressionnés par la qualité de la voix synthétisée. On décida alors de mettre le système à disposition du public sous le nom de Schwätzmaschinn.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eLa responsabilité technique fut ensuite confiée à Christopher Morse, nouveau collaborateur du ZLS, spécialisé dans les technologies IA, qui adapta le modèle pour la production. Après quelques mois, le TTS fut installé sur les ordinateurs du gouvernement, aux côtés du système de reconnaissance vocale schreifmaschinn.lu (ASR), inauguré le 9 décembre 2022. Le projet prit finalement le nom Liesmaschinn.lu, intégré dans le portail combiné Sproochmaschinn.lu.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eLe 10 février 2025, le ministre de la Culture, Eric Thill, a présenté officiellement cette plateforme vocale à la presse.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003c/p\u003e\n\n\n\u003cdiv class=\"wp-block-image\"\u003e\n\u003cfigure class=\"aligncenter size-full\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" width=\"1006\" height=\"990\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/liesmaschinn.png\" alt=\"\" class=\"wp-image-2631\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/liesmaschinn.png 1006w, https://admin.ki-leierbud.lu/wp-content/uploads/liesmaschinn-300x295.png 300w, https://admin.ki-leierbud.lu/wp-content/uploads/liesmaschinn-768x756.png 768w\" sizes=\"auto, (max-width: 1006px) 100vw, 1006px\" /\u003e\u003cfigcaption class=\"wp-element-caption\"\u003eLiesmaschinn vum ZLS (Februar 2025)\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003cp\u003e\u003c/p\u003e\n\n\n\n\u003ch4 class=\"wp-block-heading\"\u003eLes évolutions récentes\u003c/h4\u003e\n\n\n\n\u003cp\u003e\u003cbr\u003eL’évolution exponentielle de l’IA fait que les grandes étapes se comptent désormais en mois plutôt qu’en années.\u003c/p\u003e\n\n\n\n\u003cul class=\"wp-block-list\"\u003e\n\u003cli\u003eDécembre 2023 : Coqui-AI annonce sa fermeture et ses services disparaissent progressivement.\u003c/li\u003e\n\n\n\n\u003cli\u003eMars 2025 : le gouvernement lance un appel d’offres pour le projet ScreenReaderLB, destiné à remplacer le module eSpeak-NG luxembourgeois dans les lecteurs d’écran pour malvoyants.\u003c/li\u003e\n\n\n\n\u003cli\u003e15 avril 2025 : RTL et l’Université du Luxembourg annoncent le lancement de LuxVoice, un projet de recherche financé par le Fonds National de la Recherche (FNR). L’objectif est de développer un système de synthèse vocale luxembourgeois à la fois expressif sur le plan émotionnel et riche sur le plan linguistique. Les responsables du projet sont :\n\u003cul class=\"wp-block-list\"\u003e\n\u003cli\u003eNina Hossemi-Kivanani, cheffe de projet chez RTL\u003c/li\u003e\n\n\n\n\u003cli\u003eTom Weber, CTO de RTL\u003c/li\u003e\n\n\n\n\u003cli\u003ePeter Gilles, conseiller scientifique à l’Université du Luxembourg\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\n\n\n\u003cli\u003eMai 2025 : Michel Hansen (alias Synesthesiam), ancien contributeur au projet Coqui-TTS, publie une nouvelle version de son modèle luxembourgeois Piper TTS.\u003c/li\u003e\n\n\n\n\u003cli\u003eJuin 2025 : la start-up luxembourgeoise SoftGiant TTS présente son premier modèle luxembourgeois. Malheureusement, la licence de la base du ZLS utilisée pour l’entraînement ne permet pas une exploitation commerciale.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003e\u003c/p\u003e\n\n\n\n\u003cfigure class=\"wp-block-gallery has-nested-images columns-default is-cropped wp-block-gallery-1 is-layout-flex wp-block-gallery-is-layout-flex\"\u003e\n\u003cfigure class=\"wp-block-image size-large\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" width=\"900\" height=\"986\" data-id=\"2636\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/piper.png\" alt=\"\" class=\"wp-image-2636\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/piper.png 900w, https://admin.ki-leierbud.lu/wp-content/uploads/piper-274x300.png 274w, https://admin.ki-leierbud.lu/wp-content/uploads/piper-768x841.png 768w\" sizes=\"auto, (max-width: 900px) 100vw, 900px\" /\u003e\u003cfigcaption class=\"wp-element-caption\"\u003eLuxembourgish TTS model Piper by Synesthesiam\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cfigure class=\"wp-block-image size-large\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" width=\"900\" height=\"984\" data-id=\"2635\" src=\"https://admin.ki-leierbud.lu/wp-content/uploads/softgiant.png\" alt=\"\" class=\"wp-image-2635\" srcset=\"https://admin.ki-leierbud.lu/wp-content/uploads/softgiant.png 900w, https://admin.ki-leierbud.lu/wp-content/uploads/softgiant-274x300.png 274w, https://admin.ki-leierbud.lu/wp-content/uploads/softgiant-768x840.png 768w\" sizes=\"auto, (max-width: 900px) 100vw, 900px\" /\u003e\u003cfigcaption class=\"wp-element-caption\"\u003eLuxembourgish TTS model by SoftGiant\u003c/figcaption\u003e\u003c/figure\u003e\n\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003c/p\u003e\n","colors":{"header":"#003366","main":"#E6F2FF","footer":"#004080","headerFont":"#FFFFFF","mainFont":"#000000","footerFont":"#FFFFFF"},"links":{"login":"https://www.web3.lu/ki-leierbud/login.html","about":"https://www.web3.lu/ki-leierbud/about.html","welcome":"https://www.web3.lu/ki-leierbud/welcome.html","search":"https://www.web3.lu/ki-leierbud/search.html","landing":"https://www.web3.lu/ki-leierbud/landing.html","dashboard":"https://www.web3.lu/ki-leierbud/dashboard.html","faq":"https://www.web3.lu/ki-leierbud/faq.html","user":"https://www.web3.lu/ki-leierbud/user.html","author":"https://www.web3.lu/ki-leierbud/author.html"},"logo":"assets/logo.svg","favicon":"assets/logo.svg","lang":"fr","langOptions":[{"lc":"fr","id":"2518"}],"prevHref":"/histoire/fr/2511/","nextHref":"/histoire/fr/2536/","position":"6/12","authorInitials":"MB"},"__N_SSG":true},"page":"/[lang]/[slug]","query":{"lang":"fr","slug":"2518"},"buildId":"rQNnZtZ66eHWK4CySTAhx","assetPrefix":"/histoire","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>